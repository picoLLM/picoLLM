[build-system]
requires = ["setuptools>=42", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "picollm"
version = "1.0.0"
description = "Python client for Anthropic and OpenAI (compatible) LLM engines"
readme = "README.md"
requires-python = ">=3.12"
license = "CC0-1.0"
authors = [
 {name = "Tim Dolan", email = "timmydolan21@gmail.com"}
]
urls = {Homepage = "https://github.com/picollm/picollm"}
dependencies = [
    "torch",
    "pydantic",
    "requests",
    "uvicorn",
    "tdqm==0.0.1",
    "spacy==3.8.2",
    "numpy",
    "httpx==0.28.1",
    "fastapi[all]==0.115.8",
    "argparse==1.4.0",
    "psycopg2-binary==2.9.10",
    "sqlalchemy==2.0.37",
    "transformers==4.48.2",
    "datasets==3.2.0",
    "databases[postgresql]==0.9.0",
    "python-dotenv==1.0.1",
    "qdrant-client==1.13.2",
    "sse_starlette==2.2.1",
    "ollama==0.4.7",
    "openai",
    "beautifulsoup4",
    "anthropic>=0.52.1",
    "readability-lxml==0.8.4.1",
    "sentence-transformers[onnx]==5.0.0",
]

[project.optional-dependencies]
cpu = ["torch",]

[tool.uv.sources]
# The torch, torchvision, and torchaudio packages are installed from the pytorch-cpu and pytorch-cu124 indexes
torch = [
 { index = "pytorch-cpu", extra = "cpu" },
# { index = "pytorch-cu124", extra = "cu124" },
]

[[tool.uv.index]]
# The pytorch-cpu index is used to install the torch, torchvision, and torchaudio packages
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

# [[tool.uv.index]]
# name = "pytorch-cu124"
# url = "https://download.pytorch.org/whl/cu124"
# explicit = true

[tool.setuptools]
packages = ["picollm", "picollm.providers", "picollm.models", "picollm.utils"]

[tool.setuptools.package-dir]
"picollm" = "."
"picollm.providers" = "./providers"
"picollm.models" = "./models"
"picollm.utils" = "./utils"
